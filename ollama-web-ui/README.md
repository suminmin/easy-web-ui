# web-ui with ollama

```
docker compose up
```

```
sh run_ollama.sh [LLM model | default = llama3.2:1b]
```
